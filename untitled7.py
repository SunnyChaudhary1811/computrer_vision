# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VBj1-07EZC7KxrCMxnKtlmmYdy7sYUuQ
"""

import tensorflow as tf
import tensorflow_datasets as tfds

builder = tfds.builder("plant_village")
builder.download_and_prepare()
ds_info = builder.info

# Split the dataset into training and testing subsets
(train_ds, test_ds) = tfds.load("plant_village", split=["train[:80%]", "train[80%:]"], as_supervised=True)

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Load PlantVillage dataset
builder = tfds.builder("plant_village")
builder.download_and_prepare()
ds_info = builder.info

# Split the dataset into training and testing subsets
(train_ds, test_ds) = tfds.load("plant_village", split=["train[:80%]", "train[80%:]"], as_supervised=True)

# Define preprocessing function
def preprocess_image(image, label):
    image = tf.image.resize(image, (224, 224))  # Resize to input size of the CNN model
    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values to [0, 1]
    return image, label

# Apply preprocessing and batch datasets
batch_size = 32
train_ds = train_ds.map(preprocess_image).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.map(preprocess_image).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

# Define and compile the model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(512, activation='relu'),
    layers.Dense(ds_info.features['label'].num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
num_epochs = 20
model.fit(train_ds, epochs=num_epochs)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_ds)
print(f'Test accuracy: {test_accuracy}')

